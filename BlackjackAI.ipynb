{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmyuX+6omyjT9L2rTtsKbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank731/blackjack-ai/blob/main/BlackjackAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements:"
      ],
      "metadata": {
        "id": "T1lxzLgChlzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3\n",
        "!pip install gymnasium"
      ],
      "metadata": {
        "id": "qzl-c-k9kF_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blackjack Environment"
      ],
      "metadata": {
        "id": "gIfBfrbQnJuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from gymnasium import Env\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "\n",
        "DECK_COUNT = 1\n",
        "\n",
        "class BlackjackEnv(Env):\n",
        "    def __init__(self, render_mode=\"console\"):\n",
        "        '''\n",
        "        self.action_space = spaces.Dict({\n",
        "            \"move\": spaces.Discrete(3), # 0 stand, 1 hit, 2 double down\n",
        "            \"bet_amount\": spaces.Discrete(cur_funds) # Betting amount\n",
        "        })\n",
        "        '''\n",
        "        self.action_space = spaces.Discrete(2) # 0 stand 1 hit\n",
        "        self.observation_space = spaces.Dict({\n",
        "            \"player_score\": spaces.Discrete(22), # Player score\n",
        "            \"player_hand\": spaces.MultiDiscrete([14] * 7), # Player's hand, 0 is no card\n",
        "            \"dealer_card\": spaces.Discrete(14),  # Dealer's showing card\n",
        "            \"player_ace\": spaces.Discrete(2),   # Whether the player has a usable Ace\n",
        "            \"played_cards\": spaces.MultiDiscrete([14] * (13 * 4 * DECK_COUNT)) # Discarded cards\n",
        "            #\"cur_funds\": spaces.Discrete(1e9) # Current funds\n",
        "        })\n",
        "        #self.initial_funds = cur_funds\n",
        "        #self.cur_funds = cur_funds\n",
        "        #self.bet_amount = None\n",
        "        self.deck = None\n",
        "        self.player_hand = None\n",
        "        self.dealer_hand = None\n",
        "        self.played_cards = None\n",
        "        self.player_ace = None\n",
        "        self.render_mode = render_mode\n",
        "    def reset(self, seed=None,\n",
        "        options=None):\n",
        "        super().reset(seed=seed)\n",
        "        #self.cur_funds = self.initial_funds\n",
        "        #self.bet_amount = 0\n",
        "        self.played_cards = []\n",
        "        self.deck = self.create_deck()\n",
        "        self.reset_game()\n",
        "        return self._get_obs(), {}\n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "        terminated = False\n",
        "        if action:\n",
        "            self.add_card(True)\n",
        "            if self.calculate_hand_value(self.player_hand) > 21:\n",
        "                reward = -1\n",
        "                terminated = self.reset_game()\n",
        "        else:\n",
        "            while self.calculate_hand_value(self.dealer_hand) < 17:\n",
        "                self.add_card(False)\n",
        "            player_value = self.calculate_hand_value(self.player_hand)\n",
        "            dealer_value = self.calculate_hand_value(self.dealer_hand)\n",
        "            if player_value > 21:\n",
        "                reward = -1\n",
        "            elif dealer_value > 21:\n",
        "                reward = 1\n",
        "            elif player_value > dealer_value:\n",
        "                reward = 1\n",
        "            elif dealer_value > player_value:\n",
        "                reward = -1\n",
        "            terminated = self.reset_game()\n",
        "        return self._get_obs(), reward, terminated, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode == \"console\":\n",
        "            print(\"Player: \")\n",
        "            self.print_hand(self.player_hand)\n",
        "            print(\"Dealer: \")\n",
        "            self.print_hand(self.dealer_hand)\n",
        "\n",
        "    def close(self):\n",
        "        return super().close()\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return {\"player_score\": self.calculate_hand_value(self.player_hand), \"player_hand\": np.array(self.player_hand + [0] * 7)[:7], \"dealer_card\": self.dealer_hand[0], \"player_ace\": int(self.player_ace), \"dealer_ace\": int(self.dealer_ace), \"played_cards\": np.array(self.played_cards + [0] * 13 * 4 * DECK_COUNT)[:13 * 4 * DECK_COUNT]}\n",
        "\n",
        "    def reset_game(self):\n",
        "        if len(self.deck) < 10:\n",
        "            return True\n",
        "        self.player_hand = []\n",
        "        self.dealer_hand = []\n",
        "        self.player_ace = False\n",
        "        self.dealer_ace = False\n",
        "        self.add_card(True, 2)\n",
        "        self.add_card(False, 2)\n",
        "        return False\n",
        "\n",
        "    def add_card(self, player, count=1):\n",
        "        for i in range(count):\n",
        "            card = self.deck.pop()\n",
        "            self.played_cards.append(card)\n",
        "            if player:\n",
        "                self.player_hand.append(card)\n",
        "                if card == 1:\n",
        "                    self.player_ace = True\n",
        "            else:\n",
        "                self.dealer_hand.append(card)\n",
        "            if len(self.deck) < 20:\n",
        "                self.deck = self.create_deck()\n",
        "                self.played_cards = []\n",
        "\n",
        "    def create_deck(self):\n",
        "        # Create a deck of cards\n",
        "        deck = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] * 4 * DECK_COUNT\n",
        "        random.shuffle(deck)\n",
        "        return deck\n",
        "\n",
        "    def get_card_value(self, card):\n",
        "        # Return the numerical value of a card\n",
        "        if card > 10:\n",
        "            return 10\n",
        "        elif card == 1:\n",
        "            return 11\n",
        "        else:\n",
        "            return card\n",
        "\n",
        "    def calculate_hand_value(self, hand):\n",
        "        # Calculate the value of a hand\n",
        "        value = sum(self.get_card_value(card) for card in hand)\n",
        "        # Adjust for aces\n",
        "        num_aces = sum(1 for card in hand if card == 1)\n",
        "        while value > 21 and num_aces > 0:\n",
        "            value -= 10\n",
        "            num_aces -= 1\n",
        "        return value\n",
        "\n",
        "    def print_hand(self, hand):\n",
        "        # Print the cards in a hand\n",
        "        print(hand)\n",
        "        print(\"Current score: {}\".format(self.calculate_hand_value(hand)))\n"
      ],
      "metadata": {
        "id": "0aQDsInpnLCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Environment"
      ],
      "metadata": {
        "id": "m1rjVVWPj_2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from gymnasium import Env\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "\n",
        "DECK_COUNT = 1\n",
        "\n",
        "class BlackjackTestEnv(BlackjackEnv):\n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "        terminated = False\n",
        "        if action:\n",
        "            print(\"Hit\")\n",
        "            self.render()\n",
        "            self.add_card(True)\n",
        "            if self.calculate_hand_value(self.player_hand) > 21:\n",
        "                print(\"Busted, lose\")\n",
        "                reward = -1\n",
        "                terminated = self.reset_game()\n",
        "        else:\n",
        "            print(\"Stand\")\n",
        "            while self.calculate_hand_value(self.dealer_hand) < 17:\n",
        "                self.add_card(False)\n",
        "                self.render()\n",
        "            player_value = self.calculate_hand_value(self.player_hand)\n",
        "            dealer_value = self.calculate_hand_value(self.dealer_hand)\n",
        "            if player_value > 21:\n",
        "                reward = -1\n",
        "                print(\"Busted, lose\")\n",
        "            elif dealer_value > 21:\n",
        "                reward = 1\n",
        "                print(\"Dealer busted, win\")\n",
        "            elif player_value > dealer_value:\n",
        "                reward = 1\n",
        "                print(\"Win\")\n",
        "            elif dealer_value > player_value:\n",
        "                reward = -1\n",
        "                print(\"Lose\")\n",
        "            terminated = self.reset_game()\n",
        "        return self._get_obs(), reward, terminated, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode == \"console\":\n",
        "            print(\"Player: \")\n",
        "            self.print_hand(self.player_hand)\n",
        "            print(\"Dealer: \")\n",
        "            self.print_hand(self.dealer_hand)"
      ],
      "metadata": {
        "id": "TPu399WKkCUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "aEtPE5FFnD8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.dqn.dqn import DQN\n",
        "#from blackjack import BlackjackEnv\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "env = BlackjackEnv()\n",
        "#env.reset()\n",
        "#env.step(1)\n",
        "#print(env._get_obs())\n",
        "model = DQN(\"MultiInputPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=1e5, progress_bar=True)\n",
        "model.save(\"DQN_blackjack\")\n",
        "\n",
        "#vec_env = model.get_env()\n",
        "#obs = vec_env.reset()\n",
        "#for i in range(1000):\n",
        "#    action, _state = model.predict(obs, deterministic=True)\n",
        "#    obs, reward, done, info = vec_env.step(action)\n",
        "#    vec_env.render()\n",
        "#check_env(env, warn=True)"
      ],
      "metadata": {
        "id": "6EZVvklynC3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "ZhBEG2WIrWvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.dqn.dqn import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "test_env = BlackjackTestEnv()\n",
        "model = DQN.load(\"DQN_blackjack\", env=test_env)\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=1)\n",
        "print(mean_reward, std_reward)\n",
        "#env = BlackjackEnv()\n",
        "#vec_env = model.get_env()\n",
        "#obs = vec_env.reset()\n",
        "#for i in range(1000):\n",
        "#    action, _state = model.predict(obs, deterministic=True)\n",
        "#    obs, reward, done, info = vec_env.step(action)\n",
        "#check_env(env, warn=True)\n",
        "\n",
        "#print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "vbj33NWkrBRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}